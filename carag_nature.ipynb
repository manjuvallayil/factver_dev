{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qsh5523/miniconda3/envs/factver_env/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for allenai/scifact contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/allenai/scifact\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Claim_id                                         Claim_text\n",
      "0         0  0-dimensional biomaterials lack inductive prop...\n",
      "1         2  1 in 5 million in UK have abnormal PrP positiv...\n",
      "2         4  1-1% of colorectal cancer patients are diagnos...\n",
      "3         6  10% of sudden infant death syndrome (SIDS) dea...\n",
      "4         9  32% of liver transplantation programs required...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load SciFact claims and corpus\n",
    "claims_dataset = load_dataset('allenai/scifact', 'claims', split='train')\n",
    "corpus_dataset = load_dataset('allenai/scifact', 'corpus', split='train')\n",
    "\n",
    "# Extract claims and evidence texts\n",
    "claims_id = []\n",
    "claims_data = []\n",
    "evidence_ids = []\n",
    "evidence_titles = []\n",
    "evidence_data = []\n",
    "\n",
    "# Iterate through the claims dataset and extract the claim text and corresponding evidence (i.e., abstracts from the corpus)\n",
    "for example in claims_dataset:\n",
    "    claim_id = example['id']\n",
    "    claim_text = example['claim']\n",
    "    claims_id.append(claim_id)\n",
    "    claims_data.append(claim_text)\n",
    "    \n",
    "for example in corpus_dataset:   \n",
    "    # Collect all evidence title and text from the corpus based on doc_id\n",
    "    evidence_id = example['doc_id']\n",
    "    evidence_title = example['title']\n",
    "    evidence_text = example['abstract']\n",
    "    evidence_ids.append(evidence_id)\n",
    "    evidence_titles.append(evidence_title)\n",
    "    evidence_data.append(' '.join(evidence_text))  # All evidence is now a single combined string\n",
    "\n",
    "# Create a DataFrames for claims and evidence texts\n",
    "claims_df = pd.DataFrame({\n",
    "    'Claim_id': claims_id,\n",
    "    'Claim_text': claims_data,\n",
    "})\n",
    "evidence_df = pd.DataFrame({\n",
    "    'id' : evidence_ids,\n",
    "    'title' : evidence_titles,\n",
    "    'abstract': evidence_data,\n",
    "})\n",
    "\n",
    "print(claims_df.head())  # Preview of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150aa1c7ca6a49d48ac6a0d5a8fdccc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n",
      "INFO:root:Classification model loaded on CUDA\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n",
      "/home/qsh5523/miniconda3/envs/factver_env/lib/python3.10/site-packages/transformers/models/bart/configuration_bart.py:179: UserWarning:\n",
      "\n",
      "Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGUtils initialized with embedding model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from utils.dataUtils import DataUtils\n",
    "from utils.modelUtils import ModelUtils\n",
    "from utils.limeUtils import LIMEUtils\n",
    "from utils.graphUtils import create_and_save_graph, draw_cluster_graph, draw_soi\n",
    "from utils.soiUtils import SOIUtils\n",
    "from utils.ragUtils_scifact import RAGUtils\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Parameters\n",
    "model_name = 'MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'\n",
    "embedding_model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "llama_model_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "# Paths for RAGUtils\n",
    "passages_path = '/home/qsh5523/Documents/factver_dev/scifact/dataset'\n",
    "index_path = '/home/qsh5523/Documents/factver_dev/scifact/faiss/index.faiss'\n",
    "\n",
    "#selected_claim_id = 'Claim_10'\n",
    "similarity_threshold = 0.75  # delta for cosine similarity\n",
    "alpha = 0.5  # parameter for weighted vector combination of thematic embedding\n",
    "n_docs = 6  # number of docs to retrieve by RAG\n",
    "n_components_carag_u = 10  # number of clusters for CARAG-U\n",
    "\n",
    "# Initialize LLaMA model\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_name)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(llama_model_name)\n",
    "\n",
    "# Initialize utilities\n",
    "#data_utils = DataUtils(dataset_name)\n",
    "model_utils = ModelUtils(model_name, embedding_model_name)\n",
    "lime_utils = LIMEUtils(model_utils)\n",
    "soi_utils = SOIUtils(model_utils)\n",
    "rag_utils = RAGUtils(passages_path, index_path, embedding_model_name)\n",
    "print(\"RAGUtils initialized with embedding model:\", rag_utils.embedding_model)\n",
    "\n",
    "# Function to generate LLM-based explanation\n",
    "def generate_llm_summary(claim, evidences):\n",
    "    # Clear the GPU cache first\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    combined_evidence = ' '.join([evidence for evidence in evidences])\n",
    "    prompt = f\"Claim: {claim}\\nEvidence: {combined_evidence}\\nYou are a fact verification assistant. From the given Claim and its Evidence, determine if the claim is supported by the evidence and generate a concise explanation (two sentences max).\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs = llama_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        outputs = llama_model.generate(inputs['input_ids'], max_new_tokens=200)\n",
    "    \n",
    "    return llama_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704204e3fac74de88e11512e94df0f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique clusters identified in the dataset: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# --- Setup ---\n",
    "selected_claim_id = 9  # Example ID from SciFact\n",
    "\n",
    "# Step 1: Prepare full pool of texts for embedding (claims + evidence abstracts)\n",
    "claims_pool = claims_df[['Claim_id', 'Claim_text']].copy()\n",
    "evidence_pool = evidence_df[['id', 'title']].copy()\n",
    "\n",
    "# Create a unified text pool\n",
    "embedding_texts = []\n",
    "embedding_sources = []  # To track whether it's a claim or evidence\n",
    "\n",
    "# Add claim texts\n",
    "for _, row in claims_pool.iterrows():\n",
    "    embedding_texts.append(row['Claim_text'])\n",
    "    embedding_sources.append({'type': 'claim', 'id': row['Claim_id']})\n",
    "\n",
    "# Add evidence abstracts\n",
    "for _, row in evidence_pool.iterrows():\n",
    "    embedding_texts.append(row['title'])\n",
    "    embedding_sources.append({'type': 'evidence_title', 'id': row['id']})\n",
    "\n",
    "# Step 2: Generate embeddings\n",
    "embeddings = model_utils.get_sent_embeddings(embedding_texts)\n",
    "\n",
    "# Step 3: Clustering\n",
    "labels_carag_u = model_utils.cluster_embeddings(embeddings, n_components=n_components_carag_u)\n",
    "unique_labels_carag_u = set(labels_carag_u)\n",
    "print(f\"Unique clusters identified in the dataset: {unique_labels_carag_u}\")\n",
    "\n",
    "\n",
    "# Step 4: Map each item to its cluster\n",
    "cluster_map = []\n",
    "for idx, source in enumerate(embedding_sources):\n",
    "    cluster_map.append({\n",
    "        'index': idx,\n",
    "        'type': source['type'],\n",
    "        'id': source['id'],\n",
    "        'text': embedding_texts[idx],\n",
    "        'cluster': labels_carag_u[idx]\n",
    "    })\n",
    "\n",
    "cluster_map_df = pd.DataFrame(cluster_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_soi_scifact_carag_u(selected_claim_id, cluster_map_df, selected_cluster_id, model_utils, similarity_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Computes the Subset of Interest (SOI) for SciFact using CARAG-U logic, working directly with cluster_map_df.\n",
    "\n",
    "    :param selected_claim_id: ID of the selected claim.\n",
    "    :param cluster_map_df: DataFrame containing cluster mapping for claims and evidence titles.\n",
    "    :param selected_cluster_id: The cluster ID of the selected claim.\n",
    "    :param model_utils: Module for embedding and clustering utilities.\n",
    "    :param similarity_threshold: Cosine similarity threshold for selecting relevant evidences.\n",
    "    :return: Dictionary with claim, refined evidences, and similarity scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Get selected claim text\n",
    "    selected_row = cluster_map_df[(cluster_map_df['type'] == 'claim') & (cluster_map_df['id'] == selected_claim_id)]\n",
    "    if selected_row.empty:\n",
    "        raise ValueError(f\"Claim ID {selected_claim_id} not found in cluster map.\")\n",
    "\n",
    "    selected_claim_text = selected_row.iloc[0]['text']\n",
    "\n",
    "    # Step 2: Extract evidence titles in the same cluster\n",
    "    cluster_evidence_rows = cluster_map_df[\n",
    "        (cluster_map_df['type'] == 'evidence_title') &\n",
    "        (cluster_map_df['cluster'] == selected_cluster_id)\n",
    "    ]\n",
    "\n",
    "    cluster_evidences = [(row['text'], f\"Evidence_{row['id']}\") for _, row in cluster_evidence_rows.iterrows()]\n",
    "\n",
    "    # Step 3: Compute claim embedding\n",
    "    claim_embedding = model_utils.get_embeddings([selected_claim_text])[0]\n",
    "\n",
    "    soi = {\n",
    "        'claim_id': selected_claim_id,\n",
    "        'claim': selected_claim_text,\n",
    "        'refined_cluster_evidences': [],\n",
    "        'similarities': []\n",
    "    }\n",
    "\n",
    "    # Step 4: Refine cluster evidences based on similarity\n",
    "    for evidence_text, evidence_id in cluster_evidences:\n",
    "        evidence_embedding = model_utils.get_embeddings([evidence_text])[0]\n",
    "        similarity = cosine_similarity(\n",
    "            claim_embedding.reshape(1, -1),\n",
    "            evidence_embedding.reshape(1, -1)\n",
    "        )[0][0]\n",
    "\n",
    "        if similarity > similarity_threshold:\n",
    "            soi['refined_cluster_evidences'].append((evidence_text, evidence_id))\n",
    "            soi['similarities'].append((selected_claim_text, evidence_text, similarity))\n",
    "\n",
    "    return soi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected claim (ID 9) belongs to cluster 8\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Find selected claim's cluster ID\n",
    "selected_row = cluster_map_df[(cluster_map_df['type'] == 'claim') & (cluster_map_df['id'] == selected_claim_id)]\n",
    "\n",
    "if not selected_row.empty:\n",
    "    selected_cluster_id_carag_u = selected_row.iloc[0]['cluster']\n",
    "    print(f\"Selected claim (ID {selected_claim_id}) belongs to cluster {selected_cluster_id_carag_u}\")\n",
    "\n",
    "    # Step 7: Compute SOI\n",
    "    soi_output = compute_soi_scifact_carag_u(\n",
    "        selected_claim_id=selected_claim_id,\n",
    "        cluster_map_df=cluster_map_df,\n",
    "        selected_cluster_id=selected_cluster_id_carag_u,\n",
    "        model_utils=model_utils,\n",
    "        similarity_threshold=0.5  # or whatever threshold suits your use case\n",
    "    )\n",
    "    soi_evidences = soi_output['refined_cluster_evidences']\n",
    "\n",
    "    \"\"\"\n",
    "    # Step 8: Display or use output\n",
    "    print(\"\\n--- Subset of Interest (SOI) ---\")\n",
    "    print(f\"Claim: {soi_output['claim']}\")\n",
    "    print(\"Relevant evidences:\")\n",
    "    for evidence_text, evidence_id in soi_output['refined_cluster_evidences']:\n",
    "        print(f\" - ({evidence_id}) {evidence_text}\")\n",
    "    \"\"\"\n",
    "else:\n",
    "    print(f\"Claim ID {selected_claim_id} not found in cluster map.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6365817df7dd435d9e57202a44fe6fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Although drugs are intended to be selective, at least some bind to several physiological targets, explaining side effects and efficacy. Because many drug-target combinations exist, it would be useful to explore possible interactions computationally. Here we compared 3,665 US Food and Drug Administration (FDA)-approved and investigational drugs against hundreds of targets, defining each target by its ligands. Chemical similarities between drugs and ligand sets predicted thousands of unanticipated associations. Thirty were tested experimentally, including the antagonism of the beta(1) receptor by the transporter inhibitor Prozac, the inhibition of the 5-hydroxytryptamine (5-HT) transporter by the ion channel drug Vadilex, and antagonism of the histamine H(4) receptor by the enzyme inhibitor Rescriptor. Overall, 23 new drug-target associations were confirmed, five of which were potent (<100 nM). The physiological relevance of one, the drug N,N-dimethyltryptamine (DMT) on serotonergic receptors, was confirmed in a knockout mouse. The chemical similarity approach is systematic and comprehensive, and may suggest side-effects and new indications for many drugs. Membrane attack complex/perforin-like (MACPF) proteins comprise the largest superfamily of pore-forming proteins, playing crucial roles in immunity and pathogenesis. Soluble monomers assemble into large transmembrane pores via conformational transitions that remain to be structurally and mechanistically characterised. Here we present an 11 Å resolution cryo-electron microscopy (cryo-EM) structure of the two-part, fungal toxin Pleurotolysin (Ply), together with crystal structures of both components (the lipid binding PlyA protein and the pore-forming MACPF component PlyB). These data reveal a 13-fold pore 80 Å in diameter and 100 Å in height, with each subunit comprised of a PlyB molecule atop a membrane bound dimer of PlyA. The resolution of the EM map, together with biophysical and computational experiments, allowed confident assignment of subdomains in a MACPF pore assembly. The major conformational changes in PlyB are a ∼70° opening of the bent and distorted central β-sheet of the MACPF domain, accompanied by extrusion and refolding of two α-helical regions into transmembrane β-hairpins (TMH1 and TMH2). We determined the structures of three different disulphide bond-trapped prepore intermediates. Analysis of these data by molecular modelling and flexible fitting allows us to generate a potential trajectory of β-sheet unbending. The results suggest that MACPF conformational change is triggered through disruption of the interface between a conserved helix-turn-helix motif and the top of TMH2. Following their release we propose that the transmembrane regions assemble into β-hairpins via top down zippering of backbone hydrogen bonds to form the membrane-inserted β-barrel. The intermediate structures of the MACPF domain during refolding into the β-barrel pore establish a structural paradigm for the transition from soluble monomer to pore, which may be conserved across the whole superfamily. The TMH2 region is critical for the release of both TMH clusters, suggesting why this region is targeted by endogenous inhibitors of MACPF function. Chromosome 7q36 microdeletion syndrome is a rare genomic disorder characterized by underdevelopment of the brain, microcephaly, anomalies of the sex organs, and language problems. Developmental delay, intellectual disability, autistic spectrum disorders, BDMR syndrome, and unusual facial morphology are the key features of the chromosome 2q37 microdeletion syndrome. A genetic screening for two brothers with global developmental delay using high-resolution chromosomal analysis and subtelomeric multiplex ligation-dependent probe amplification revealed subtelomeric rearrangements on the same sites of 2q37.2 and 7q35, with reversed deletion and duplication. Both of them showed dysmorphic facial features, severe disability of physical and intellectual development, and abnormal genitalia with differential abnormalities in their phenotypes. The family did not have abnormal genetic phenotypes. According to the genetic analysis of their parents, adjacent-1 segregation from their mother's was suggested as a mechanism of their gene mutation. By comparing the phenotypes of our patients with previous reports on similar patients, we tried to obtain the information of related genes and their chromosomal locations. OBJECTIVES To identify and describe misunderstandings between patients and doctors associated with prescribing decisions in general practice.   \\n DESIGN Qualitative study.   \\n SETTING 20 general practices in the West Midlands and south east England.   \\n PARTICIPANTS 20 general practitioners and 35 consulting patients.   \\n MAIN OUTCOME MEASURES Misunderstandings between patients and doctors that have potential or actual adverse consequences for taking medicine.   \\n RESULTS 14 categories of misunderstanding were identified relating to patient information unknown to the doctor, doctor information unknown to the patient, conflicting information, disagreement about attribution of side effects, failure of communication about doctor's decision, and relationship factors. All the misunderstandings were associated with lack of patients' participation in the consultation in terms of the voicing of expectations and preferences or the voicing of responses to doctors' decisions and actions. They were all associated with potential or actual adverse outcomes such as non-adherence to treatment. Many were based on inaccurate guesses and assumptions. In particular doctors seemed unaware of the relevance of patients' ideas about medicines for successful prescribing.   \\n CONCLUSIONS Patients' participation in the consultation and the adverse consequences of lack of participation are important. The authors are developing an educational intervention that builds on these findings. CONTEXT Bioterrorist attacks involving letters and mail-handling systems in Washington, DC, resulted in Bacillus anthracis (anthrax) spore contamination in the Hart Senate Office Building and other facilities in the US Capitol's vicinity.   \\n OBJECTIVE To provide information about the nature and extent of indoor secondary aerosolization of B anthracis spores.   \\n DESIGN Stationary and personal air samples, surface dust, and swab samples were collected under semiquiescent (minimal activities) and then simulated active office conditions to estimate secondary aerosolization of B anthracis spores. Nominal size characteristics, airborne concentrations, and surface contamination of B anthracis particles (colony-forming units) were evaluated.   \\n RESULTS Viable B anthracis spores reaerosolized under semiquiescent conditions, with a marked increase in reaerosolization during simulated active office conditions. Increases were observed for B anthracis collected on open sheep blood agar plates (P<.001) and personal air monitors (P =.01) during active office conditions. More than 80% of the B anthracis particles collected on stationary monitors were within an alveolar respirable size range of 0.95 to 3.5 micro m.   CONCLUSIONS Bacillus anthracis spores used in a recent terrorist incident reaerosolized under common office activities. These findings have important implications for appropriate respiratory protection, remediation, and reoccupancy of contaminated office environments. Trypanosoma brucei, the causative agent of African sleeping sickness, is transmitted to its mammalian host by the tsetse. In the fly, the parasite's surface is covered with invariant procyclin, while in the mammal it resides extracellularly in its bloodstream form (BF) and is densely covered with highly immunogenic Variant Surface Glycoprotein (VSG). In the BF, the parasite varies this highly immunogenic surface VSG using a repertoire of ~2500 distinct VSG genes. Recent reports in mammalian systems point to a role for histone acetyl-lysine recognizing bromodomain proteins in the maintenance of stem cell fate, leading us to hypothesize that bromodomain proteins may maintain the BF cell fate in trypanosomes. Using small-molecule inhibitors and genetic mutants for individual bromodomain proteins, we performed RNA-seq experiments that revealed changes in the transcriptome similar to those seen in cells differentiating from the BF to the insect stage. This was recapitulated at the protein level by the appearance of insect-stage proteins on the cell surface. Furthermore, bromodomain inhibition disrupts two major BF-specific immune evasion mechanisms that trypanosomes harness to evade mammalian host antibody responses. First, monoallelic expression of the antigenically varied VSG is disrupted. Second, rapid internalization of antibodies bound to VSG on the surface of the trypanosome is blocked. Thus, our studies reveal a role for trypanosome bromodomain proteins in maintaining bloodstream stage identity and immune evasion. Importantly, bromodomain inhibition leads to a decrease in virulence in a mouse model of infection, establishing these proteins as potential therapeutic drug targets for trypanosomiasis. Our 1.25Å resolution crystal structure of a trypanosome bromodomain in complex with I-BET151 reveals a novel binding mode of the inhibitor, which serves as a promising starting point for rational drug design.\"]\n"
     ]
    }
   ],
   "source": [
    "# Compute aggregated embedding for CARAG-U SOI\n",
    "aggregated_embedding = rag_utils.compute_aggregated_embedding([evidence for evidence, _ in soi_evidences])\n",
    "# Retrieve evidence using CARAG-U's dataset-wide embedding\n",
    "retrived_evidence, retrieved_doc_ids, retrieved_doc_ids_original  = rag_utils.retrieve_evidence(claim_text, n_docs, aggregated_embedding, alpha)\n",
    "#explanation = generate_llm_summary(claim_text, retrived_evidence)\n",
    "#print(\"\\nPost Hoc Explanation:\\n\", explanation)\n",
    "print(retrived_evidence)\n",
    "#print(retrieved_doc_ids_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None]\n"
     ]
    }
   ],
   "source": [
    "def get_original_doc_ids(retrieved_titles, evidence_df):\n",
    "    doc_ids = []\n",
    "    for title in retrieved_titles:\n",
    "        match = evidence_df[evidence_df['title'] == title]\n",
    "        if not match.empty:\n",
    "            doc_ids.append(match.iloc[0]['id'])\n",
    "        else:\n",
    "            doc_ids.append(None)\n",
    "    return doc_ids\n",
    "\n",
    "ids = get_original_doc_ids(retrived_evidence, evidence_df)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factver_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
