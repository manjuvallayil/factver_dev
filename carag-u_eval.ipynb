{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971a6d33a03a4dc3b74bdfba64ecfaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n",
      "INFO:root:Classification model loaded on CUDA\n",
      "/home/qsh5523/miniconda3/envs/factver_env/lib/python3.10/site-packages/transformers/models/bart/configuration_bart.py:179: UserWarning:\n",
      "\n",
      "Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim ID Claim_59 is valid and exists in the dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777a7cbdbef640548aeb141dc49e8c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique clusters identified in the dataset: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "Graph created with 3685 nodes and 3030 edges.\n",
      "The selected claim (Claim_59) belongs to cluster 8\n",
      "\n",
      "RAG Explanation:\n",
      " Claim: The public is unconcerned about a climate emergency\n",
      "Evidence: Failure will result in the country's once-successful car making industry being largely consigned to the scrap heap. They could drive back to Israel and get a ferry around the middle east to Qatar - but that is a two-week journey which would have meant missing Wales' first match. Shares fell as low as $6.50-apiece on Monday, down 97 percent from August 2021.BMW-branded cars, motorcycles, and Mini models sold since October 1 get the new warranty. Cho Tae-yong, ambassador of the Republic of Korea to the U.S., said Tuesday officials are discussing “several possible options” to correct what the country believes to be unfair policies that eliminated up to $7,500 of tax credits for EVs produced outside North America. White House press secretary Karine Jean-Pierre wrote Biden is ¡°asymptomatic, feeling fine, and working in isolation from the Residence to protect others.¡± White House press secretary Karine Jean-Pierre wrote Biden is ¡°asymptomatic, feeling fine, and working in isolation from the Residence to protect others.¡±\n",
      "You are a fact verification assistant. From the given Claim and its Evidence, determine if the claim is supported by the evidence and generate a concise explanation (two sentences max).\n",
      "The claim is not supported by the evidence. While the evidence mentions the potential impact of climate change on the car making industry and the country's response to it, it does not suggest that the public is unconcerned about the climate emergency. In fact, the evidence highlights the country's efforts to correct what it believes to be unfair policies regarding electric vehicles produced outside North America, indicating that the country is taking steps to address the issue.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb81d1800344e3c838278d0b29eabb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CARAG_U Explanation:\n",
      " Claim: The public is unconcerned about a climate emergency\n",
      "Evidence: Failure will result in the country's once-successful car making industry being largely consigned to the scrap heap. This greenhouse gas trading scheme forms part of the UK government's ambition to achieve net zero emissions by 2050.Global business is increasingly familiar with the prospect of short-notice public investigatory attention, whether from regulators, law enforcement, political forces or as a consequence of sanctions, and this can  in in some cases  devastate individual and corporate reputation. Cho Tae-yong, ambassador of the Republic of Korea to the U.S., said Tuesday officials are discussing “several possible options” to correct what the country believes to be unfair policies that eliminated up to $7,500 of tax credits for EVs produced outside North America. They could drive back to Israel and get a ferry around the middle east to Qatar - but that is a two-week journey which would have meant missing Wales' first match. After two and a half years of intensive negotiations, I am pleased about the inclusion of maritime shipping in European emissions trading and the creation of an innovation fund for more sustainable shipping and the protection of maritime habitats, she said. That would leave Britain reliant on imports from other big producers such as China, the US and Europe, which have raced ahead with the help of big state subsidies.\n",
      "You are a fact verification assistant. From the given Claim and its Evidence, determine if the claim is supported by the evidence and generate a concise explanation (two sentences max).\n",
      "The claim is not supported by the evidence. Although the evidence mentions the potential impact of a greenhouse gas trading scheme on the UK's car making industry, it does not suggest that the public is unconcerned about a climate emergency. In fact, the evidence highlights the importance of addressing climate change and the inclusion of maritime shipping in European emissions trading.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from utils.dataUtils import DataUtils\n",
    "from utils.modelUtils import ModelUtils\n",
    "from utils.limeUtils import LIMEUtils\n",
    "from utils.graphUtils import create_and_save_graph, draw_cluster_graph, draw_soi\n",
    "from utils.soiUtils import SOIUtils\n",
    "from utils.ragUtils import RAGUtils\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Parameters\n",
    "dataset_name = 'manjuvallayil/factver_master'\n",
    "model_name = 'MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'\n",
    "embedding_model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "llama_model_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "selected_claim_id = 'Claim_59'\n",
    "similarity_threshold = 0.75  # delta for cosine similarity\n",
    "alpha = 0.5  # para for weighted vector combination of thematic embedding (1 for RAG only)\n",
    "n_docs = 6  # number of docs to retrieve by RAG\n",
    "n_components= 10 # number of clusters to from through gmm-em\n",
    "\n",
    "# Paths for RAGUtils\n",
    "passages_path = '/home/qsh5523/Documents/factver_dev/dataset'\n",
    "index_path = '/home/qsh5523/Documents/factver_dev/faiss/index.faiss'\n",
    "\n",
    "# Initialize LLaMA model\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_name)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(llama_model_name)\n",
    "\n",
    "# Initialize utilities\n",
    "data_utils = DataUtils(dataset_name)\n",
    "model_utils = ModelUtils(model_name, embedding_model_name)\n",
    "lime_utils = LIMEUtils(model_utils)\n",
    "soi_utils = SOIUtils(model_utils)\n",
    "rag_utils = RAGUtils(passages_path, index_path, embedding_model_name)\n",
    "\n",
    "# Function to generate LLM-based explanation\n",
    "def generate_llm_summary(claim, evidences):\n",
    "    # Clear the GPU cache first\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    combined_evidence = ' '.join([evidence for evidence in evidences])\n",
    "    prompt = f\"Claim: {claim}\\nEvidence: {combined_evidence}\\nYou are a fact verification assistant. From the given Claim and its Evidence, determine if the claim is supported by the evidence and generate a concise explanation (two sentences max).\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs = llama_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        outputs = llama_model.generate(inputs['input_ids'], max_new_tokens=200)\n",
    "    \n",
    "    return llama_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "# Load data without theme-based filtering\n",
    "grouped_data = data_utils.get_full_data(selected_claim_id)\n",
    "\n",
    "# GMM-EM Clustering\n",
    "# Check if data is available\n",
    "if grouped_data.empty:\n",
    "    print(\"No data found in the dataset.\")\n",
    "else:\n",
    "    # Get embeddings\n",
    "    all_texts = [row['Claim_text'] for _, row in grouped_data.iterrows()]\n",
    "    for _, row in grouped_data.iterrows():\n",
    "        all_texts.extend(row['Evidence_text'])\n",
    "\n",
    "    embeddings = model_utils.get_sent_embeddings(all_texts)\n",
    "\n",
    "    # Apply GMM-EM clustering to dataset\n",
    "    labels = model_utils.cluster_embeddings(embeddings, n_components)\n",
    "    unique_labels = set(labels)\n",
    "    print(f\"Unique clusters identified in the dataset: {unique_labels}\")\n",
    "\n",
    "    # Draw and save cluster graph\n",
    "    graph_filepath = 'graph.pkl'\n",
    "    create_and_save_graph(model_utils, grouped_data, graph_filepath)\n",
    "\n",
    "    #for cluster_id in unique_labels:\n",
    "        #draw_cluster_graph(grouped_data, labels, cluster_id=cluster_id, model_utils=model_utils, title=f'Cluster Visualization {cluster_id}')\n",
    "\n",
    "    # Ensure the selected claim is in the identified cluster\n",
    "    selected_cluster_id = None\n",
    "    claim_text = None\n",
    "\n",
    "    for index, row in grouped_data.iterrows():\n",
    "        unique_id = row['Claim_topic_id'].split('_')[-1]\n",
    "        if f\"Claim_{unique_id}\" == selected_claim_id:\n",
    "            selected_cluster_id = labels[index]\n",
    "            claim_text = row['Claim_text']\n",
    "            break\n",
    "\n",
    "    if selected_cluster_id is not None:\n",
    "        print(f\"The selected claim ({selected_claim_id}) belongs to cluster {selected_cluster_id}\")\n",
    "\n",
    "        # Compare RAG (alpha=1.0) vs CARAG_U (alpha=0.5)\n",
    "\n",
    "        # 1. RAG-based retrieval and explanation\n",
    "        rag_evidence = rag_utils.retrieve_evidence(claim_text, n_docs, aggregated_embedding=None, alpha=1.0)\n",
    "        rag_explanation = generate_llm_summary(claim_text, rag_evidence)\n",
    "        print(\"\\nRAG Explanation:\\n\", rag_explanation)\n",
    "        \n",
    "        # Compute the SOI using CARAG_U\n",
    "        soi = soi_utils.compute_soi_carag_u(selected_claim_id, grouped_data, labels, selected_cluster_id, similarity_threshold)\n",
    "        soi_evidences = soi['refined_cluster_evidences']\n",
    "        #draw_soi(soi, similarity_threshold, title=f'SOI Visualization for {selected_claim_id}')\n",
    "\n",
    "        # Compute aggregated embedding for the SOI evidences\n",
    "        aggregated_embedding = rag_utils.compute_aggregated_embedding([evidence for evidence, _ in soi_evidences])\n",
    "        \n",
    "        # 2. Generate explanation using CARAG_U (retrieved evidence with combined embedding)\n",
    "        agg_evidence = rag_utils.retrieve_evidence(claim_text, n_docs, aggregated_embedding, alpha=0.5)\n",
    "        carag_u_explanation = generate_llm_summary(claim_text, agg_evidence)\n",
    "        print(\"\\nCARAG_U Explanation:\\n\", carag_u_explanation)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Selected claim {selected_claim_id} is not part of any identified cluster.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81dd04a34e04ad5ab38ea4c81b003a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n",
      "INFO:root:Classification model loaded on CUDA\n",
      "/home/qsh5523/miniconda3/envs/factver_env/lib/python3.10/site-packages/transformers/models/bart/configuration_bart.py:179: UserWarning:\n",
      "\n",
      "Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The selected Claim belongs to the theme: Climate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837ed640412e429a9e6704e99dbca240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique clusters identified within the theme Climate: {0, 1, 2}\n",
      "The selected claim (Claim_59) belongs to cluster 1\n",
      "\n",
      "RAG Explanation:\n",
      " Claim: The public is unconcerned about a climate emergency\n",
      "Evidence: Failure will result in the country's once-successful car making industry being largely consigned to the scrap heap. They could drive back to Israel and get a ferry around the middle east to Qatar - but that is a two-week journey which would have meant missing Wales' first match. Shares fell as low as $6.50-apiece on Monday, down 97 percent from August 2021.BMW-branded cars, motorcycles, and Mini models sold since October 1 get the new warranty. Cho Tae-yong, ambassador of the Republic of Korea to the U.S., said Tuesday officials are discussing “several possible options” to correct what the country believes to be unfair policies that eliminated up to $7,500 of tax credits for EVs produced outside North America. White House press secretary Karine Jean-Pierre wrote Biden is ¡°asymptomatic, feeling fine, and working in isolation from the Residence to protect others.¡± White House press secretary Karine Jean-Pierre wrote Biden is ¡°asymptomatic, feeling fine, and working in isolation from the Residence to protect others.¡±\n",
      "You are a fact verification assistant. From the given Claim and its Evidence, determine if the claim is supported by the evidence and generate a concise explanation (two sentences max).\n",
      "The claim is not supported by the evidence. While the evidence does mention the potential impact of climate change on the car making industry and the country's economy, it does not suggest that the public is unconcerned about a climate emergency. In fact, the evidence highlights the growing demand for electric vehicles and the potential for the industry to adapt to the changing climate.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b933ae39a540ac8da1cd15dbf57e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CARAG Explanation:\n",
      " Claim: The public is unconcerned about a climate emergency\n",
      "Evidence: Failure will result in the country's once-successful car making industry being largely consigned to the scrap heap. This greenhouse gas trading scheme forms part of the UK government's ambition to achieve net zero emissions by 2050.Global business is increasingly familiar with the prospect of short-notice public investigatory attention, whether from regulators, law enforcement, political forces or as a consequence of sanctions, and this can  in in some cases  devastate individual and corporate reputation. Cho Tae-yong, ambassador of the Republic of Korea to the U.S., said Tuesday officials are discussing “several possible options” to correct what the country believes to be unfair policies that eliminated up to $7,500 of tax credits for EVs produced outside North America. They could drive back to Israel and get a ferry around the middle east to Qatar - but that is a two-week journey which would have meant missing Wales' first match. After two and a half years of intensive negotiations, I am pleased about the inclusion of maritime shipping in European emissions trading and the creation of an innovation fund for more sustainable shipping and the protection of maritime habitats, she said. That would leave Britain reliant on imports from other big producers such as China, the US and Europe, which have raced ahead with the help of big state subsidies.\n",
      "You are a fact verification assistant. From the given Claim and its Evidence, determine if the claim is supported by the evidence and generate a concise explanation (two sentences max).\n",
      "The claim is not supported by the evidence. While the evidence does mention the potential negative impact of the UK's carbon trading scheme on the country's car making industry, it does not suggest that the public is unconcerned about a climate emergency. In fact, the evidence highlights the importance of addressing climate change through various means, including the inclusion of maritime shipping in European emissions trading and the creation of an innovation fund for more sustainable shipping and the protection of maritime habitats.\n",
      "Claim ID Claim_59 is valid and exists in the dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5979d5cd016c418cb03fee8b8721e52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique clusters identified in the dataset: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "The selected claim (Claim_59) belongs to cluster 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d0db2a8ce44d5fb83b1c80ae4e8143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CARAG_U Explanation:\n",
      " Claim: The public is unconcerned about a climate emergency\n",
      "Evidence: Failure will result in the country's once-successful car making industry being largely consigned to the scrap heap. This greenhouse gas trading scheme forms part of the UK government's ambition to achieve net zero emissions by 2050.Global business is increasingly familiar with the prospect of short-notice public investigatory attention, whether from regulators, law enforcement, political forces or as a consequence of sanctions, and this can  in in some cases  devastate individual and corporate reputation. Cho Tae-yong, ambassador of the Republic of Korea to the U.S., said Tuesday officials are discussing “several possible options” to correct what the country believes to be unfair policies that eliminated up to $7,500 of tax credits for EVs produced outside North America. They could drive back to Israel and get a ferry around the middle east to Qatar - but that is a two-week journey which would have meant missing Wales' first match. After two and a half years of intensive negotiations, I am pleased about the inclusion of maritime shipping in European emissions trading and the creation of an innovation fund for more sustainable shipping and the protection of maritime habitats, she said. That would leave Britain reliant on imports from other big producers such as China, the US and Europe, which have raced ahead with the help of big state subsidies.\n",
      "You are a fact verification assistant. From the given Claim and its Evidence, determine if the claim is supported by the evidence and generate a concise explanation (two sentences max).\n",
      "The claim is not supported by the evidence. The evidence provided highlights the potential impact of the greenhouse gas trading scheme on the UK's car making industry, but does not suggest that the public is unconcerned about a climate emergency. In fact, the evidence suggests the opposite, as it mentions the inclusion of maritime shipping in European emissions trading and the creation of an innovation fund for more sustainable shipping and the protection of maritime habitats, which demonstrates a growing awareness and concern about climate change.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from utils.dataUtils import DataUtils\n",
    "from utils.modelUtils import ModelUtils\n",
    "from utils.limeUtils import LIMEUtils\n",
    "from utils.graphUtils import create_and_save_graph, draw_cluster_graph, draw_soi\n",
    "from utils.soiUtils import SOIUtils\n",
    "from utils.ragUtils import RAGUtils\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Parameters\n",
    "dataset_name = 'manjuvallayil/factver_master'\n",
    "model_name = 'MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'\n",
    "embedding_model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "llama_model_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "selected_claim_id = 'Claim_59'\n",
    "similarity_threshold = 0.75  # delta for cosine similarity\n",
    "alpha = 0.5  # parameter for weighted vector combination of thematic embedding\n",
    "n_docs = 6  # number of docs to retrieve by RAG\n",
    "n_components_carag = 3  # number of clusters for CARAG\n",
    "n_components_carag_u = 10  # number of clusters for CARAG-U\n",
    "\n",
    "# Paths for RAGUtils\n",
    "passages_path = '/home/qsh5523/Documents/factver_dev/dataset'\n",
    "index_path = '/home/qsh5523/Documents/factver_dev/faiss/index.faiss'\n",
    "\n",
    "# Initialize LLaMA model\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_name)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(llama_model_name)\n",
    "\n",
    "# Initialize utilities\n",
    "data_utils = DataUtils(dataset_name)\n",
    "model_utils = ModelUtils(model_name, embedding_model_name)\n",
    "lime_utils = LIMEUtils(model_utils)\n",
    "soi_utils = SOIUtils(model_utils)\n",
    "rag_utils = RAGUtils(passages_path, index_path, embedding_model_name)\n",
    "\n",
    "# Function to generate LLM-based explanation\n",
    "def generate_llm_summary(claim, evidences):\n",
    "    # Clear the GPU cache first\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    combined_evidence = ' '.join([evidence for evidence in evidences])\n",
    "    prompt = f\"Claim: {claim}\\nEvidence: {combined_evidence}\\nYou are a fact verification assistant. From the given Claim and its Evidence, determine if the claim is supported by the evidence and generate a concise explanation (two sentences max).\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs = llama_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        outputs = llama_model.generate(inputs['input_ids'], max_new_tokens=200)\n",
    "    \n",
    "    return llama_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "\n",
    "\n",
    "# Load themed data\n",
    "theme, themed_data = data_utils.filter_by_theme(selected_claim_id)\n",
    "\n",
    "# CARAG: Themed data clustering\n",
    "if not themed_data.empty:\n",
    "    # Get embeddings for themed data\n",
    "    all_texts = [row['Claim_text'] for _, row in themed_data.iterrows()]\n",
    "    for _, row in themed_data.iterrows():\n",
    "        all_texts.extend(row['Evidence_text'])\n",
    "    \n",
    "    embeddings = model_utils.get_sent_embeddings(all_texts)\n",
    "    \n",
    "    # Apply GMM-EM clustering to themed data\n",
    "    labels_carag = model_utils.cluster_embeddings(embeddings, n_components=n_components_carag)\n",
    "    unique_labels_carag = set(labels_carag)\n",
    "    print(f\"Unique clusters identified within the theme {theme}: {unique_labels_carag}\")\n",
    "\n",
    "    # Ensure the selected claim is in the identified cluster\n",
    "    selected_cluster_id_carag = None\n",
    "    claim_text = None\n",
    "\n",
    "    for index, row in themed_data.iterrows():\n",
    "        unique_id = row['Claim_topic_id'].split('_')[-1]\n",
    "        if f\"Claim_{unique_id}\" == selected_claim_id:\n",
    "            selected_cluster_id_carag = labels_carag[index]\n",
    "            claim_text = row['Claim_text']\n",
    "            break\n",
    "\n",
    "    if selected_cluster_id_carag is not None:\n",
    "        print(f\"The selected claim ({selected_claim_id}) belongs to cluster {selected_cluster_id_carag}\")\n",
    "\n",
    "        # 1. RAG-based retrieval and explanation (AS BASELINE)\n",
    "        rag_evidence = rag_utils.retrieve_evidence(claim_text, n_docs, aggregated_embedding=None, alpha=1.0)\n",
    "        rag_explanation = generate_llm_summary(claim_text, rag_evidence)\n",
    "        print(\"\\nRAG Explanation:\\n\", rag_explanation)\n",
    "        \n",
    "        # 2. CARAG-based retrieval and explanation\n",
    "        carag_soi = soi_utils.compute_soi(selected_claim_id, themed_data, labels_carag, selected_cluster_id_carag, similarity_threshold)\n",
    "        carag_soi_evidences = carag_soi['related_claims'] + carag_soi['annotated_evidences'] + carag_soi['thematic_cluster_evidences']\n",
    "\n",
    "        # Compute aggregated embedding for CARAG SOI\n",
    "        carag_aggregated_embedding = rag_utils.compute_aggregated_embedding([evidence for evidence, _ in carag_soi_evidences])\n",
    "        \n",
    "        # Retrieve evidence using CARAG's SOI-based embedding\n",
    "        carag_evidence = rag_utils.retrieve_evidence(claim_text, n_docs, carag_aggregated_embedding, alpha=0.5)\n",
    "        carag_explanation = generate_llm_summary(claim_text, carag_evidence)\n",
    "        print(\"\\nCARAG Explanation:\\n\", carag_explanation)\n",
    "    else:\n",
    "        print(f\"Selected claim {selected_claim_id} is not part of any identified cluster in CARAG.\")\n",
    "\n",
    "else:\n",
    "    print(f\"No data found for the theme of claim {selected_claim_id}.\")\n",
    "\n",
    "# CARAG-U: Dataset-wide clustering\n",
    "grouped_data = data_utils.get_full_data(selected_claim_id)\n",
    "\n",
    "if not grouped_data.empty:\n",
    "    # Get embeddings for dataset-wide clustering\n",
    "    all_texts = [row['Claim_text'] for _, row in grouped_data.iterrows()]\n",
    "    for _, row in grouped_data.iterrows():\n",
    "        all_texts.extend(row['Evidence_text'])\n",
    "    \n",
    "    embeddings = model_utils.get_sent_embeddings(all_texts)\n",
    "    \n",
    "    # Apply GMM-EM clustering to the full dataset\n",
    "    labels_carag_u = model_utils.cluster_embeddings(embeddings, n_components=n_components_carag_u)\n",
    "    unique_labels_carag_u = set(labels_carag_u)\n",
    "    print(f\"Unique clusters identified in the dataset: {unique_labels_carag_u}\")\n",
    "\n",
    "    # Ensure the selected claim is in the identified cluster\n",
    "    selected_cluster_id_carag_u = None\n",
    "\n",
    "    for index, row in grouped_data.iterrows():\n",
    "        unique_id = row['Claim_topic_id'].split('_')[-1]\n",
    "        if f\"Claim_{unique_id}\" == selected_claim_id:\n",
    "            selected_cluster_id_carag_u = labels_carag_u[index]\n",
    "            break\n",
    "\n",
    "    if selected_cluster_id_carag_u is not None:\n",
    "        print(f\"The selected claim ({selected_claim_id}) belongs to cluster {selected_cluster_id_carag_u}\")\n",
    "\n",
    "        # 3. CARAG-U-based retrieval and explanation\n",
    "        carag_u_soi = soi_utils.compute_soi_carag_u(selected_claim_id, grouped_data, labels_carag_u, selected_cluster_id_carag_u, similarity_threshold)\n",
    "        carag_u_soi_evidences = carag_u_soi['refined_cluster_evidences']\n",
    "\n",
    "        # Compute aggregated embedding for CARAG-U SOI\n",
    "        carag_u_aggregated_embedding = rag_utils.compute_aggregated_embedding([evidence for evidence, _ in carag_u_soi_evidences])\n",
    "        \n",
    "        # Retrieve evidence using CARAG-U's dataset-wide embedding\n",
    "        carag_u_evidence = rag_utils.retrieve_evidence(claim_text, n_docs, carag_u_aggregated_embedding, alpha=0.5)\n",
    "        carag_u_explanation = generate_llm_summary(claim_text, carag_u_evidence)\n",
    "        print(\"\\nCARAG_U Explanation:\\n\", carag_u_explanation)\n",
    "    else:\n",
    "        print(f\"Selected claim {selected_claim_id} is not part of any identified cluster in CARAG-U.\")\n",
    "\n",
    "else:\n",
    "    print(\"No data found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim ID Claim_59 is valid and exists in the dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c945bc4195f74eb9b4cb9fc2f986e427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering dataset using GMM-EM...\n",
      "Clustering complete. 6 clusters identified.\n",
      "Claim Claim_59 assigned to cluster 0 with text: The public is unconcerned about a climate emergency\n",
      "SOI extracted with 65 related claims and 231 thematic evidences.\n",
      "SOI extracted for claim Claim_59:\n",
      "- Related claims: 65\n",
      "- Cluster evidences: 231\n",
      "Aggregated embedding computed successfully.\n"
     ]
    }
   ],
   "source": [
    "selected_claim_id = 'Claim_59'\n",
    "# Load full grouped data and validate the claim ID\n",
    "grouped_data = data_utils.get_full_data(selected_claim_id)\n",
    "\n",
    "# Check if grouped data is available\n",
    "if grouped_data.empty:\n",
    "    print(\"No data found or the selected claim ID is invalid.\")\n",
    "else:\n",
    "    # Prepare texts for clustering\n",
    "    all_texts = []\n",
    "    index_mapping = []  # Track indices for claims and evidences\n",
    "    for index, row in grouped_data.iterrows():\n",
    "        index_mapping.append((index, 'claim'))  # Mark as claim\n",
    "        all_texts.append(row['Claim_text'])\n",
    "        for i, evidence in enumerate(row['Evidence_text']):\n",
    "            index_mapping.append((index, f'evidence_{i}'))  # Mark as evidence\n",
    "            all_texts.append(evidence)\n",
    "\n",
    "    # Generate embeddings\n",
    "    embeddings = model_utils.get_sent_embeddings(all_texts)\n",
    "\n",
    "    # Perform GMM-EM clustering\n",
    "    cluster_labels = model_utils.perform_clustering_carag_u(embeddings,n_clusters=6)\n",
    "\n",
    "    # Map cluster labels to grouped data\n",
    "    cluster_mapping = {}\n",
    "    for i, (row_index, text_type) in enumerate(index_mapping):\n",
    "        if row_index not in cluster_mapping:\n",
    "            cluster_mapping[row_index] = []\n",
    "        cluster_mapping[row_index].append((text_type, cluster_labels[i]))\n",
    "\n",
    "    # Identify the selected claim's cluster and text\n",
    "    selected_cluster_id = None\n",
    "    claim_text = None\n",
    "    for index, row in grouped_data.iterrows():\n",
    "        unique_id = row['Claim_topic_id'].split('_')[-1]\n",
    "        if f\"Claim_{unique_id}\" == selected_claim_id:\n",
    "            claim_clusters = cluster_mapping[index]\n",
    "            selected_cluster_id = next(\n",
    "                (label for label_type, label in claim_clusters if label_type == 'claim'), None\n",
    "            )\n",
    "            claim_text = row['Claim_text']\n",
    "            print(f\"Claim {selected_claim_id} assigned to cluster {selected_cluster_id} with text: {claim_text}\")\n",
    "            break\n",
    "\n",
    "    if selected_cluster_id is None or claim_text is None:\n",
    "        print(f\"Claim {selected_claim_id} not found or not assigned to any cluster.\")\n",
    "    else:\n",
    "        # Compute the Subset of Interest (SOI)\n",
    "        soi = soi_utils.compute_soi_carag_u(\n",
    "            selected_claim_id, grouped_data, cluster_labels, selected_cluster_id, similarity_threshold=0.75\n",
    "        )\n",
    "        print(f\"SOI extracted for claim {selected_claim_id}:\")\n",
    "        print(f\"- Related claims: {len(soi['related_claims'])}\")\n",
    "        print(f\"- Cluster evidences: {len(soi['cluster_evidences'])}\")\n",
    "\n",
    "        # Compute aggregated embedding for the SOI\n",
    "        aggregated_embedding = soi_utils.calculate_aggregate_embedding_carag_u(soi)\n",
    "        print(\"Aggregated embedding computed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving evidence using CARAG-U...\n",
      "\n",
      "CARAG-U Retrieved Evidence:\n",
      "['with immunity levels against flu also lower in many people after two years of lower flu circulation Amazon initially invested $700 million in Rivian in 2019 and later introduced its first electric delivery van, designed and built with the EV startup. Such is the reality of some 5% of global Covid-19 survivors who have now developed long-lasting taste and smell problems, according to a 2022 study. Such is the reality of some 5% of global Covid-19 survivors who have now developed long-lasting taste and smell problems, according to a 2022 study. The renovated space ¡ª representing more than 150 years of Jacksonville¡¯s Black history ¡ª celebrated its grand reopening on Tuesday, Nov. 8, 2022. The renovated space ¡ª representing more than 150 years of Jacksonville¡¯s Black history ¡ª celebrated its grand reopening on Tuesday, Nov. 8, 2022.']\n",
      "\n",
      "Generating CARAG-U explanation...\n",
      "\n",
      "CARAG-U Explanation:\n",
      "Claim: The public is unconcerned about a climate emergency\n",
      "Evidence: with immunity levels against flu also lower in many people after two years of lower flu circulation Amazon initially invested $700 million in Rivian in 2019 and later introduced its first electric delivery van, designed and built with the EV startup. Such is the reality of some 5% of global Covid-19 survivors who have now developed long-lasting taste and smell problems, according to a 2022 study. Such is the reality of some 5% of global Covid-19 survivors who have now developed long-lasting taste and smell problems, according to a 2022 study. The renovated space ¡ª representing more than 150 years of Jacksonville¡¯s Black history ¡ª celebrated its grand reopening on Tuesday, Nov. 8, 2022. The renovated space ¡ª representing more than 150 years of Jacksonville¡¯s Black history ¡ª celebrated its grand reopening on Tuesday, Nov. 8, 2022.\n",
      "You are a fact verification assistant. From the given Claim and its Evidence, determine if the claim is supported by the evidence and generate a concise explanation (two sentences max).\n",
      "The claim is not supported by the evidence. While the evidence does show that immunity levels against flu are lower in many people after two years of lower flu circulation, it does not provide any information about the public's concern level regarding a climate emergency. Additionally, the evidence provided does not directly address the claim made in the prompt.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve evidence using CARAG-U\n",
    "print(\"Retrieving evidence using CARAG-U...\")\n",
    "carag_u_evidence = rag_utils.retrieve_evidence(\n",
    "    claim=claim_text, \n",
    "    aggregated_embedding=aggregated_embedding,\n",
    "    alpha=0.25\n",
    ")\n",
    "print(f\"\\nCARAG-U Retrieved Evidence:\\n{carag_u_evidence}\")\n",
    "\n",
    "# Generate CARAG-U explanation\n",
    "print(\"\\nGenerating CARAG-U explanation...\")\n",
    "carag_u_explanation = generate_llm_summary(claim_text, carag_u_evidence)\n",
    "print(f\"\\nCARAG-U Explanation:\\n{carag_u_explanation}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRY 3D VISUALIZATIONS and DYNAMIC CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factver_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
